{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7200d1",
   "metadata": {},
   "source": [
    "# THE EFFECT OF PURE METAL'S ATOMIC PROPERTIES AND SURFACE CHARACTERISTICS ON ITS WORK FUNCTION: AN ANALYSIS USING SUPPORT VECTOR REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba479a",
   "metadata": {},
   "source": [
    "## Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b08a1",
   "metadata": {},
   "source": [
    "### Installing Library Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278547f",
   "metadata": {},
   "source": [
    "This prediction  model is coded using Python 3.13.9. All the libraries that required can be installed using this cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11323760",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3dd2f4",
   "metadata": {},
   "source": [
    "### Importing Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bfc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mp_api.client import MPRester\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from pymatgen.core import Structure\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, root_mean_squared_error as rmse\n",
    "from scipy.stats import loguniform\n",
    "import shap\n",
    "from PyALE import ale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "MP_API_KEY = \"oaqaUyUUgOtqC6jLsILaljDuuUEvrX89\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bc78d",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0bcef",
   "metadata": {},
   "source": [
    "### Data from Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MPRester(MP_API_KEY) as mpr:\n",
    "    # Memilih material logam yang dibentuk oleh 1 unsur dan teramati lewat eksperimen\n",
    "    summary_docs = mpr.materials.summary._search(\n",
    "        is_metal = True,\n",
    "        theoretical = False,\n",
    "        nelements = [1, 1],\n",
    "        fields = [\"material_id\", \"nsites\", \"volume\", \"structure\", \"symmetry\"]\n",
    "    )\n",
    "    summary_structures = {str(doc.material_id): doc.structure for doc in summary_docs}\n",
    "\n",
    "    # Mengubah data struktur ke sel konvensional\n",
    "    bulk_summary_conventional = {mid: s.to_conventional() for mid, s in summary_structures.items()}\n",
    "\n",
    "    material_id = [doc.material_id for doc in summary_docs]\n",
    "\n",
    "    # Menyeleksi material dari summary_docs yang sifat permukaannya telah dihitung nilainya\n",
    "    surface_properties_docs = mpr.materials.surface_properties.search(\n",
    "        material_ids = material_id,\n",
    "        fields = [\"material_id\", \"pretty_formula\", \"surfaces\", \"structure\"]\n",
    "    )\n",
    "\n",
    "    # Membuat list dari unsur-unsur yang telah dikumpulkan\n",
    "    unique_elements = list({doc.pretty_formula for doc in surface_properties_docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1146324",
   "metadata": {},
   "source": [
    "### Data from *pymatgen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valence_electrons_count(conf:str)->int: # Fungsi untuk menghitung banyaknya elektron valensi dari setiap unsur\n",
    "    patterns = r'(\\d+)([spdfgh])(\\d{1,2})'\n",
    "    subshells = re.findall(patterns,str(conf))\n",
    "    if not subshells:\n",
    "        return 0\n",
    "\n",
    "    parsed_subshells = []\n",
    "    for n, l, e in subshells:\n",
    "        try:\n",
    "            parsed_subshells.append((int(n), l, int(e)))\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not parsed_subshells:\n",
    "        return 0\n",
    "\n",
    "    max_n=max(n for n, l, e in parsed_subshells)\n",
    "\n",
    "    valence = 0\n",
    "    for n, l, e in parsed_subshells:\n",
    "        if n == max_n:\n",
    "            valence+=e\n",
    "        if l == 'd' and n == max_n - 1:\n",
    "            valence+=e\n",
    "        if l == 'f' and n == max_n - 2:\n",
    "            valence+=e\n",
    "        if l == 'g' and n == max_n - 3:\n",
    "            valence+=e\n",
    "        if l == 'h' and n == max_n - 4:\n",
    "            valence+=e\n",
    "\n",
    "    return valence\n",
    "\n",
    "sifat_atomik = []\n",
    "\n",
    "for simbol in tqdm(unique_elements):\n",
    "    try:\n",
    "        unsur = Element(simbol)\n",
    "\n",
    "        config = unsur.electronic_structure\n",
    "\n",
    "        data_unsur = {\n",
    "            'formula_pretty': simbol,\n",
    "            'atomic_number': unsur.Z,\n",
    "            'atomic_radius': unsur.atomic_radius,\n",
    "            '1st_ionization_energy_eV': unsur.ionization_energy, # Ionisasi pertama\n",
    "            'electron_affinity_eV': unsur.electron_affinity,\n",
    "            'electronegativity': unsur.X, # Skala Pauling\n",
    "            'valence_electrons': valence_electrons_count(config),\n",
    "            'Youngs_modulus': unsur.youngs_modulus,\n",
    "            'shear_modulus': unsur.rigidity_modulus,\n",
    "            'bulk_modulus': unsur.bulk_modulus\n",
    "        }\n",
    "\n",
    "        # 4. Tambahkan dictionary ke list utama\n",
    "        sifat_atomik.append(data_unsur)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Menangani jika ada data yang hilang di pymatgen (jarang terjadi)\n",
    "        print(f\"Gagal mengambil data Pymatgen untuk unsur '{simbol}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb85f83",
   "metadata": {},
   "source": [
    "### Create Dataframe using pandas + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8992308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bulk_summary_conventional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71995be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs_list = []\n",
    "for doc in summary_docs:\n",
    "    summary_docs_list.append({\n",
    "        \"material_id\": doc.material_id,\n",
    "        \"symmetry_crystal_system\": doc.symmetry.crystal_system if doc.symmetry else None,\n",
    "        \"symmetry_symbol\": doc.symmetry.symbol if doc.symmetry else None,\n",
    "        \"bulk_atomic_density\": doc.nsites / doc.volume if doc.volume else None,\n",
    "        \"c_over_a_ratio\": (doc.structure.lattice.c / doc.structure.lattice.a) if doc.structure and doc.structure.lattice and doc.structure.lattice.a else None,\n",
    "        \"b_over_a_ratio\": (doc.structure.lattice.b / doc.structure.lattice.a) if doc.structure and doc.structure.lattice and doc.structure.lattice.a else None,\n",
    "        \"lattice_alpha\": doc.structure.lattice.alpha if doc.structure and doc.structure.lattice else None,\n",
    "        \"lattice_beta\": doc.structure.lattice.beta if doc.structure and doc.structure.lattice else None,\n",
    "        \"lattice_gamma\": doc.structure.lattice.gamma if doc.structure and doc.structure.lattice else None\n",
    "    })\n",
    "\n",
    "print(summary_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_entry in summary_docs_list:\n",
    "    material_id = str(doc_entry['material_id'])\n",
    "    if material_id in bulk_summary_conventional:\n",
    "        struct = bulk_summary_conventional[material_id]\n",
    "        doc_entry.update({\n",
    "            \"bulk_atomic_density\": len(struct) / struct.volume,\n",
    "            \"c_over_a_ratio\": struct.lattice.c / struct.lattice.a,\n",
    "            \"b_over_a_ratio\": struct.lattice.b / struct.lattice.a,\n",
    "            \"lattice_alpha\": struct.lattice.alpha,\n",
    "            \"lattice_beta\": struct.lattice.beta,\n",
    "            \"lattice_gamma\": struct.lattice.gamma\n",
    "        })\n",
    "\n",
    "print(summary_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs_df = pd.DataFrame(summary_docs_list)\n",
    "\n",
    "summary_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b97633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_structure(row):\n",
    "    system = str(row['symmetry_crystal_system']).split(':')[-1].replace(\"'>\", \"\").strip()\n",
    "    symbol = str(row['symmetry_symbol'])\n",
    "\n",
    "    match (system, symbol): # Menggunakan match-case pada tuple (system, symbol)\n",
    "\n",
    "        # Kubik\n",
    "        case ('Cubic', s) if s.startswith('F'):\n",
    "            return 'FCC'\n",
    "        case ('Cubic', s) if s.startswith('I'):\n",
    "            return 'BCC'\n",
    "        case ('Cubic', s) if s.startswith('P'):\n",
    "            return 'Simple Cubic'\n",
    "\n",
    "        # Heksagonal\n",
    "        case ('Hexagonal', 'P6_3/mmc'):\n",
    "            return 'HCP' # Space group spesifik untuk HCP\n",
    "        case ('Hexagonal', 'P6/mmm'):\n",
    "            return 'Primitive Hexagonal'\n",
    "\n",
    "        # Tetragonal\n",
    "        case ('Tetragonal', s) if s.startswith('I'):\n",
    "            return 'Body-Centered Tetragonal (BCT)'\n",
    "\n",
    "        # Orthorhombic\n",
    "        case ('Orthorhombic', s) if s.startswith('C'):\n",
    "            return 'Base-Centered Orthorhombic'\n",
    "\n",
    "        # Monoclinic\n",
    "        case ('Monoclinic', s) if s.startswith('C'):\n",
    "            return 'Base-Centered Monoclinic'\n",
    "\n",
    "        # Trigonal\n",
    "        case ('Trigonal', s) if s.startswith('R'):\n",
    "            return 'Rhombohedral'\n",
    "\n",
    "        # Default\n",
    "        case _:\n",
    "            return 'Other'\n",
    "\n",
    "summary_docs_df['structure_type'] = summary_docs_df.apply(classify_structure, axis=1)\n",
    "\n",
    "cols = summary_docs_df.columns.tolist()\n",
    "structure_type_col = cols.pop(cols.index('structure_type'))\n",
    "symmetry_symbol_idx = cols.index('symmetry_symbol')\n",
    "cols.insert(symmetry_symbol_idx , structure_type_col)\n",
    "\n",
    "summary_docs_df = summary_docs_df[cols]\n",
    "\n",
    "summary_docs_df = summary_docs_df.drop(columns=['symmetry_crystal_system',])\n",
    "\n",
    "summary_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb741c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surface_properties_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_planar_density(slab_structure: Structure) -> dict:\n",
    "    \"\"\"\n",
    "    Menghitung semua data relevan dari lapisan teratas slab.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Hitung Luas (HANYA DI SINI) ---\n",
    "        a_vec = slab_structure.lattice.matrix[0]\n",
    "        b_vec = slab_structure.lattice.matrix[1]\n",
    "        surface_area_2D = np.linalg.norm(np.cross(a_vec, b_vec))\n",
    "\n",
    "        if surface_area_2D == 0:\n",
    "            return {'surface_area': 0, 'surface_atoms_count': 0, 'planar_density': np.nan}\n",
    "\n",
    "        # --- Hitung Atom ---\n",
    "        all_z_coords = [site.coords[2] for site in slab_structure.sites]\n",
    "        if not all_z_coords:\n",
    "            return {'surface_area': surface_area_2D, 'surface_atoms_count': 0, 'planar_density': np.nan}\n",
    "        max_z = max(all_z_coords)\n",
    "\n",
    "        tolerance = 0.000001\n",
    "        surface_atoms_count = 0\n",
    "        for site in slab_structure.sites:\n",
    "            if abs(site.coords[2] - max_z) < tolerance:\n",
    "                surface_atoms_count += 1\n",
    "        \n",
    "        # --- Hitung Density ---\n",
    "        planar_density = surface_atoms_count / surface_area_2D\n",
    "        \n",
    "        # Kembalikan SEMUA data\n",
    "        return planar_density\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saat menghitung data: {e}\")\n",
    "        return {'surface_area': np.nan, 'surface_atoms_count': np.nan, 'planar_density': np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_properties_lists = []\n",
    "\n",
    "for doc in tqdm(surface_properties_docs):\n",
    "    for surface in doc.surfaces:\n",
    "        cif_string = surface.structure\n",
    "        \n",
    "        # 1. Buat objek slab (tetap wajib)\n",
    "        slab_structure = Structure.from_str(cif_string, fmt=\"cif\")\n",
    "        \n",
    "        # 3. Kumpulkan hasil\n",
    "        surface_properties_lists.append({\n",
    "            'material_id': doc.material_id,\n",
    "            'pretty_formula': doc.pretty_formula,\n",
    "            'work_function': surface.work_function,\n",
    "            'miller_index': surface.miller_index,\n",
    "            'surface_energy': surface.surface_energy,\n",
    "            'fermi_energy': surface.efermi,\n",
    "            'planar_density': get_planar_density(slab_structure)\n",
    "        })\n",
    "\n",
    "surface_properties_df = pd.DataFrame(surface_properties_lists)\n",
    "\n",
    "# Tampilkan hasilnya\n",
    "print(\"DataFrame berhasil dibuat (versi bersih):\")\n",
    "surface_properties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "merged_summary_surface_df_filtered = pd.merge(\n",
    "    surface_properties_df,\n",
    "    summary_docs_df,\n",
    "    left_on=['material_id'],\n",
    "    right_on=['material_id'],\n",
    "    how='inner'  # Use 'inner' merge to keep only rows that match in both dataframes\n",
    ")\n",
    "\n",
    "merged_summary_surface_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec498c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sifat_atomik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acce2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_properties_df = pd.DataFrame(sifat_atomik)\n",
    "\n",
    "atomic_properties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08347cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df = pd.merge(\n",
    "    merged_summary_surface_df_filtered,\n",
    "    atomic_properties_df,\n",
    "    left_on = ['pretty_formula'],\n",
    "    right_on = ['formula_pretty'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "all_merged_df = all_merged_df.drop(columns = ['formula_pretty'])    \n",
    "\n",
    "all_merged_df['miller_index'] = all_merged_df['miller_index'].astype(str)\n",
    "all_merged_df['structure_type'] = all_merged_df['structure_type'].astype(str)\n",
    "all_merged_df['symmetry_symbol'] = all_merged_df['symmetry_symbol'].astype(str)\n",
    "\n",
    "all_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique structure_type: {all_merged_df['structure_type'].nunique()}\")\n",
    "print(f\"Unique miller_index: {all_merged_df['miller_index'].apply(tuple).nunique()}\")\n",
    "print(f\"Unique symmetry_symbol: {all_merged_df['symmetry_symbol'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96472a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Statistik work_function ---\")\n",
    "print(all_merged_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df.to_csv(\"metal_surface_properties_full_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2504e",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebeec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_merged_df['work_function']\n",
    "groups = all_merged_df['pretty_formula']\n",
    "\n",
    "cols_to_drop = [\n",
    "    'work_function',\n",
    "    'material_id',\n",
    "    'pretty_formula',\n",
    "    'miller_index',\n",
    "    'symmetry_symbol'\n",
    "]\n",
    "\n",
    "X_clean = all_merged_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "outer_cv = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(outer_cv.split(X_clean, y, groups=groups))\n",
    "\n",
    "X_train_outer = X_clean.iloc[train_idx]\n",
    "y_train_outer = y.iloc[train_idx]\n",
    "groups_train_outer = groups.iloc[train_idx]\n",
    "\n",
    "X_test_outer = X_clean.iloc[test_idx]\n",
    "y_test_outer = y.iloc[test_idx]\n",
    "\n",
    "print(\"--- Data Split Selesai ---\")\n",
    "print(f\"Jumlah data train (luar): {len(X_train_outer)}\")\n",
    "print(f\"Jumlah data test (luar): {len(X_test_outer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Statistik y_train_outer ---\")\n",
    "print(y_train_outer.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669e499",
   "metadata": {},
   "source": [
    "## Training, Validation, Hyperparameter Tuning, Evaluation, and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c360719",
   "metadata": {},
   "source": [
    "### Model's pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be4cd8",
   "metadata": {},
   "source": [
    "#### Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b56dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "neighbors = 5\n",
    "iteration = 125\n",
    "random_state = 42\n",
    "\n",
    "strats = [\"median\", \"knn\"]\n",
    "\n",
    "inner_cv = GroupKFold(n_splits=10)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'r2': 'r2',\n",
    "    'mae': 'neg_mean_absolute_error',\n",
    "    'rmse': 'neg_root_mean_squared_error'\n",
    "}\n",
    "\n",
    "results_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_type(X):\n",
    "    num_features_impute = X.columns[X.isnull().any()].tolist()\n",
    "    cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_features_clean = [col for col in X.columns if col not in num_features_impute + cat_features]\n",
    "    num_features = num_features_impute + num_features_clean\n",
    "    return num_features, cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3596e",
   "metadata": {},
   "source": [
    "#### Impute Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_strategy(strat, n_neighbors):\n",
    "    match strat.lower():\n",
    "        case 'knn':\n",
    "            return Pipeline(steps=[\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('imputer', KNNImputer(n_neighbors=n_neighbors))\n",
    "            ])\n",
    "        case 'median':\n",
    "            return Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "        case _:\n",
    "            raise ValueError(f\"Strategy '{strat}' unrecognized. Only accept 'knn' or 'median'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c016dad",
   "metadata": {},
   "source": [
    "#### Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(X, strategy, n_neighbors, categorical_transformer):\n",
    "    num_features, cat_features = feature_type(X)\n",
    "    imputer = imputer_strategy(strategy, n_neighbors)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', imputer, num_features),\n",
    "            ('cat', categorical_transformer, cat_features)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVR(kernel='rbf'))\n",
    "    ])\n",
    "    \n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a9ba6",
   "metadata": {},
   "source": [
    "### Model's Training, Validation, Hyperparameter Tuning, and Evaluation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344bc87",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_hyperparameter_tuning(search_mode, estimator, params, n_iter, scoring, cv, rand_state, X_train, y_train, groups_train):\n",
    "    match search_mode.lower():\n",
    "        case 'random':\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=estimator,\n",
    "                param_distributions=params,\n",
    "                n_iter=n_iter,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                refit='rmse',\n",
    "                cv=cv,\n",
    "                random_state=rand_state\n",
    "            )\n",
    "        case 'grid':\n",
    "            search = GridSearchCV(\n",
    "                estimator=estimator,\n",
    "                param_grid=params,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                refit='rmse',\n",
    "                cv=cv,\n",
    "            )\n",
    "        case _:\n",
    "            raise ValueError(f\"Search mode '{search_mode}' unrecognized. Only accept 'random' or 'grid'.\")\n",
    "    \n",
    "    model = search.fit(X_train, y_train, groups=groups_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_results(step_name, model, search_mode, strategy):\n",
    "    best_C = model.best_params_['model__C']\n",
    "    best_gamma = model.best_params_['model__gamma']\n",
    "    best_epsilon = model.best_params_['model__epsilon']\n",
    "    \n",
    "    best_idx = model.best_index_\n",
    "    best_tr_r2 = model.cv_results_['mean_test_r2'][best_idx]\n",
    "    best_tr_mae = -model.cv_results_['mean_test_mae'][best_idx]\n",
    "    best_tr_rmse = -model.cv_results_['mean_test_rmse'][best_idx]\n",
    "    \n",
    "    best_std_r2 = model.cv_results_['std_test_r2'][best_idx]\n",
    "    best_std_mae = model.cv_results_['std_test_mae'][best_idx]\n",
    "    best_std_rmse = model.cv_results_['std_test_rmse'][best_idx]\n",
    "\n",
    "    ringkasan = {\n",
    "        'Tahap': step_name, 'Search Mode': search_mode, 'Imputasi': strategy,\n",
    "        'Best C': best_C, 'Best gamma': best_gamma, 'Best epsilon': best_epsilon,\n",
    "        'CV Mean R²': best_tr_r2, 'CV Std R²': best_std_r2,\n",
    "        'CV Mean MAE': best_tr_mae, 'CV Std MAE': best_std_mae,\n",
    "        'CV Mean RMSE': best_tr_rmse, 'CV Std RMSE': best_std_rmse\n",
    "    }\n",
    "    return ringkasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_run_exp(X, step_name, search_mode, strat, n_neighbors, cat_transformer, rand_state, n_iter, params, scoring, cv, X_train, y_train, groups_train):\n",
    "    estimator = full_pipeline(X, strat, n_neighbors, cat_transformer)\n",
    "    \n",
    "    current_iter = n_iter if search_mode == 'random' else 0\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"MODE: {search_mode} | IMPUTER: {strat}\") \n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    print(f\"Starting hyperparameter tuning...\")\n",
    "    model = train_valid_hyperparameter_tuning(search_mode, estimator, params, current_iter, scoring, cv, rand_state, X_train, y_train, groups_train)\n",
    "    print(\"Hyperparameter tuning completed.\")\n",
    "    \n",
    "    ringkasan = train_results(step_name, model, search_mode, strat)\n",
    "    return model, ringkasan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866320c",
   "metadata": {},
   "source": [
    "#### Displaying Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa874a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_single_result(ringkasan):\n",
    "    print(f\"Best Hyperparameter:\")\n",
    "    for key, value in ringkasan.items():\n",
    "        if key.startswith('Best '):\n",
    "            label = key.replace('Best ', '').ljust(8)\n",
    "            print(f\" > {label} = {value}\")\n",
    "    \n",
    "    w = 10\n",
    "    metrics = ['R²', 'MAE', 'RMSE']\n",
    "    sub_headers = ['MEAN', 'STD']\n",
    "    \n",
    "    # Hitung lebar per blok metrik: spasi + MEAN(w) + \" | \" + STD(w) + spasi\n",
    "    block_width = 1 + w + 3 + w + 1\n",
    "    \n",
    "    # 1. Header Utama (Nama Metrik)\n",
    "    header_parts = [f\"{m:^{block_width}}\" for m in metrics]\n",
    "    top_header = \"|\" + \"|\".join(header_parts) + \"|\"\n",
    "    total_len = len(top_header)\n",
    "    \n",
    "    # 2. Sub Header (MEAN | STD berulang)\n",
    "    sub_header_parts = []\n",
    "    for _ in metrics:\n",
    "        sub_header_parts.append(f\" {sub_headers[0]:^{w}} | {sub_headers[1]:^{w}} \")\n",
    "    sub_header = \"|\" + \"|\".join(sub_header_parts) + \"|\"\n",
    "    \n",
    "    # 3. Isi Nilai\n",
    "    val_parts = []\n",
    "    for metric in metrics:\n",
    "        # Construct key sesuai output get_cv_best_metrics\n",
    "        key_mean = f\"CV Mean {metric}\"\n",
    "        key_std = f\"CV Std {metric}\"\n",
    "        \n",
    "        val_mean = ringkasan.get(key_mean, 0)\n",
    "        val_std = ringkasan.get(key_std, 0)\n",
    "        \n",
    "        val_parts.append(f\" {val_mean:^{w}.4f} | {val_std:^{w}.4f} \")\n",
    "\n",
    "    values_str = \"|\" + \"|\".join(val_parts) + \"|\"\n",
    "\n",
    "    print(\"-\" * total_len)\n",
    "    print(top_header)\n",
    "    print(\"-\" * total_len)\n",
    "    print(sub_header)\n",
    "    print(\"-\" * total_len)\n",
    "    print(values_str)\n",
    "    print(\"-\" * total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21367ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recap(history):\n",
    "    # Header diperlebar untuk mengakomodasi judul kolom baru\n",
    "    print(f\"{'='*115}\")\n",
    "    # Header: Menampilkan CV Mean untuk RMSE (Metrik Utama), MAE, dan R2\n",
    "    header = f\"{'TAHAP':<12} | {'MODE':<8} | {'STRAT':<8} | {'CV RMSE':^10} | {'CV MAE':^10} | {'CV R²':^10} | {'Best Params (C/Gam/Eps)':<25}\"\n",
    "    print(header)\n",
    "    print(f\"{'-'*115}\")\n",
    "    \n",
    "    sorted_history = sorted(history, key=lambda x: x['CV Mean RMSE'], reverse=False)\n",
    "    \n",
    "    for row in sorted_history:\n",
    "        step = row['Tahap'].upper()\n",
    "        mode = row['Search Mode'].upper()\n",
    "        strat = row['Imputasi'].upper()\n",
    "        \n",
    "        # Ambil nilai Mean CV\n",
    "        r2 = row.get('CV Mean R²', 0)\n",
    "        mae = row.get('CV Mean MAE', 0)\n",
    "        rmse = row.get('CV Mean RMSE', 0)\n",
    "        \n",
    "        c = row.get('Best C', 0)\n",
    "        c = f\"{c:.4f}\" if isinstance(c, (int, float)) else str(c)\n",
    "        g = row.get('Best gamma', 0)\n",
    "        g = f\"{g:.4f}\" if isinstance(g, (int, float)) else str(g)\n",
    "        e = row.get('Best epsilon', 0)\n",
    "        e = f\"{e:.4f}\" if isinstance(e, (int, float)) else str(e)\n",
    "        \n",
    "        # Format parameter agar rapi\n",
    "        params = f\"C:{c}/G:{g}/E:{e}\"\n",
    "        \n",
    "        line = f\"{step:<12} | {mode:<8} | {strat:<8} | {rmse:^10.4f} | {mae:^10.4f} | {r2:^10.4f} | {params:<25} \"\n",
    "        print(line)\n",
    "        \n",
    "    print(f\"{'='*115}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b7770",
   "metadata": {},
   "source": [
    "#### Preliminary and Final Model Comparison Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea760de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelim_comparison(X, step_name, search_mode, strats, n_neighbors, cat_transformer, rand_state, n_iter, params, scoring, cv, X_train, y_train, groups_train):\n",
    "    best_cv_score = float('inf')\n",
    "    best_candidate_info = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for mode in search_mode:\n",
    "        current_params = params.get(mode)\n",
    "        if current_params is None:\n",
    "            raise ValueError(f\"No parameters found for {mode} search mode\")\n",
    "        \n",
    "        for strat in strats:\n",
    "            model, ringkasan = single_run_exp(\n",
    "                X, step_name, mode, strat,\n",
    "                n_neighbors, cat_transformer, rand_state,\n",
    "                n_iter, current_params, scoring, cv,\n",
    "                X_train, y_train, groups_train\n",
    "            )\n",
    "            \n",
    "            display_single_result(ringkasan)\n",
    "            \n",
    "            current_score = ringkasan['CV Mean RMSE']\n",
    "            \n",
    "            if current_score < best_cv_score:\n",
    "                best_cv_score = current_score\n",
    "                best_model = model\n",
    "                best_candidate_info = ringkasan\n",
    "    \n",
    "    if best_candidate_info:\n",
    "        results_history.append(best_candidate_info)\n",
    "        print(f\"\\n>>> PRELIMINARY WINNER: {best_candidate_info['Search Mode'].upper()} - {best_candidate_info['Imputasi'].upper()}\")\n",
    "        print(f\">>> Best CV Score (Mean Validation): {best_cv_score:.4f}\")\n",
    "    \n",
    "    return best_model, best_candidate_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(d_rmse, d_mae, d_r2, d_std, tol):\n",
    "    is_candidate = False\n",
    "    reason = \"\"\n",
    "    \n",
    "    # --- 1. SELEKSI KANDIDAT (MATCH CASE) ---\n",
    "    match d_rmse:\n",
    "        # KASUS 1: RMSE Menang (Prioritas Utama)\n",
    "        case diff if diff > tol:\n",
    "            is_candidate = True\n",
    "            reason = \"RMSE improved significantly.\"\n",
    "            \n",
    "        # KASUS 2: RMSE Kalah\n",
    "        case diff if diff < -tol:\n",
    "            is_candidate = False\n",
    "            reason = \"RMSE worsened.\"\n",
    "            \n",
    "        # KASUS 3: RMSE Seri -> Cek Tie-Breaker\n",
    "        case _:\n",
    "            match (d_mae, d_r2, d_std):\n",
    "                # Tie-Breaker A: MAE\n",
    "                case (mae, _, _) if mae > tol:\n",
    "                    is_candidate = True\n",
    "                    reason = \"RMSE similar, but MAE improved.\"\n",
    "                # Tie-Breaker B: R²\n",
    "                case (mae, r2, _) if abs(mae) <= tol and r2 > tol:\n",
    "                    is_candidate = True\n",
    "                    reason = \"Error metrics similar, but R² improved.\"\n",
    "                # Tie-Breaker C: Stabilitas\n",
    "                case (mae, r2, std) if abs(mae) <= tol and abs(r2) <= tol and std > 0:\n",
    "                    is_candidate = True\n",
    "                    reason = \"Performance identical, but Stability improved.\"\n",
    "                # Tidak ada yang menang\n",
    "                case _:\n",
    "                    is_candidate = False\n",
    "                    reason = \"No significant improvement found.\"\n",
    "\n",
    "    # --- 2. SAFETY NET & KEPUTUSAN FINAL ---\n",
    "    if is_candidate:\n",
    "        # Cek apakah R2 anjlok melebihi toleransi?\n",
    "        r2_drop = -d_r2 \n",
    "        if r2_drop > tol:\n",
    "            # KENA VETO\n",
    "            final_decision = False\n",
    "            final_reason = f\"VETOED: {reason} BUT R² dropped by {r2_drop:.4f} (Exceeds {tol}).\"\n",
    "        else:\n",
    "            # LOLOS\n",
    "            final_decision = True\n",
    "            final_reason = reason\n",
    "    else:\n",
    "        # MEMANG TIDAK LOLOS DARI AWAL\n",
    "        final_decision = False\n",
    "        final_reason = reason\n",
    "        \n",
    "    return final_decision, final_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(X, step_name, search_mode, strat, n_neighbors, cat_transformer, rand_state, n_iter, params, scoring, cv, X_train, y_train, groups_train, current_model, current_candidate_info, tol):\n",
    "    best_model = current_model\n",
    "    best_candidate_info = current_candidate_info\n",
    "    \n",
    "    prev_rmse = best_candidate_info.get('CV Mean RMSE')\n",
    "    prev_mae = best_candidate_info.get('CV Mean MAE')\n",
    "    prev_r2 = best_candidate_info.get('CV Mean R²')\n",
    "    prev_std = best_candidate_info.get('CV Std RMSE')\n",
    "    \n",
    "    model, ringkasan = single_run_exp(\n",
    "        X, step_name, search_mode, strat,\n",
    "        n_neighbors, cat_transformer, rand_state, n_iter,\n",
    "        params, scoring, cv,\n",
    "        X_train, y_train, groups_train\n",
    "        )\n",
    "    \n",
    "    display_single_result(ringkasan)\n",
    "    \n",
    "    curr_rmse = ringkasan['CV Mean RMSE']\n",
    "    curr_mae = ringkasan['CV Mean MAE']\n",
    "    curr_r2 = ringkasan['CV Mean R²']\n",
    "    curr_std = ringkasan['CV Std RMSE']\n",
    "    \n",
    "    d_rmse = prev_rmse - curr_rmse  \n",
    "    d_mae = prev_mae - curr_mae     \n",
    "    d_r2 = curr_r2 - prev_r2        \n",
    "    d_std = prev_std - curr_std\n",
    "    \n",
    "    is_better, reason = comparison(d_rmse, d_mae, d_r2, d_std, tol)\n",
    "\n",
    "    if is_better:\n",
    "        print(\"\\nNew model is better\")\n",
    "        print(f\"Reason: {reason}\")\n",
    "        \n",
    "        best_model = model\n",
    "        best_candidate_info = ringkasan\n",
    "        results_history.append(ringkasan)\n",
    "    else:\n",
    "        print(\"\\nCurrent model is better\")\n",
    "        print(f\"Reason: {reason}\")\n",
    "        \n",
    "    return best_model, best_candidate_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f542",
   "metadata": {},
   "source": [
    "#### Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_implementation(X, step_name, search_mode, strats, n_neighbors, cat_transformer, rand_state, params, n_iter, scoring, cv, X_train, y_train, groups_train, current_model, current_candidate_info, tol):\n",
    "    print(f\"{'#'*60}\")\n",
    "    print(f\"{step_name.upper()} PHASE\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    \n",
    "    if step_name.lower() == \"preliminary\":\n",
    "        best_prelim_model, best_prelim_candidate_info = prelim_comparison(\n",
    "            X, step_name, search_mode, strats,\n",
    "            n_neighbors, cat_transformer, rand_state, n_iter,\n",
    "            params, scoring, cv,\n",
    "            X_train, y_train, groups_train\n",
    "        )\n",
    "        \n",
    "        display_recap(results_history)\n",
    "        return best_prelim_model, best_prelim_candidate_info\n",
    "    else:\n",
    "        best_model, best_candidate_info = final_model(\n",
    "            X, step_name, search_mode, strats,\n",
    "            n_neighbors, cat_transformer, rand_state, n_iter,\n",
    "            params, scoring, cv,\n",
    "            X_train, y_train, groups_train,\n",
    "            current_model, current_candidate_info, tol\n",
    "        )\n",
    "        \n",
    "        display_recap(results_history)\n",
    "        return best_model, best_candidate_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23340fc8",
   "metadata": {},
   "source": [
    "#### Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa01efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    te_r2 = r2(y_test, y_pred)\n",
    "    te_mae = mae(y_test, y_pred)\n",
    "    te_rmse = rmse(y_test, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'Test R²': te_r2,\n",
    "        'Test MAE': te_mae,\n",
    "        'Test RMSE': te_rmse\n",
    "    }\n",
    "    \n",
    "    return y_pred, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c5692",
   "metadata": {},
   "source": [
    "#### Preliminary Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2743a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = \"Preliminary\"\n",
    "modes = [\"random\", \"grid\"]\n",
    "tolerance = 0.001\n",
    "\n",
    "current_model = None\n",
    "current_candidate_info = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b9f31",
   "metadata": {},
   "source": [
    "##### RandomSearchCV vs GridSearchCV Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param_dist = {\n",
    "    'model__C': loguniform(1e-2, 1e2),\n",
    "    'model__gamma': loguniform(1e-2, 1e1),\n",
    "    'model__epsilon': loguniform(1e-2, 1e0)\n",
    "}\n",
    "\n",
    "coarse_param_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': [0.01, 0.1, 'scale', 1, 10],\n",
    "    'model__epsilon': [0.01, 0.05, 0.1, 0.2, 1]\n",
    "}\n",
    "\n",
    "prelim_params = {\n",
    "    'random': random_param_dist,\n",
    "    'grid': coarse_param_grid\n",
    "}\n",
    "\n",
    "prelim_best_model, prelim_best_results = full_implementation(\n",
    "    X_clean,\n",
    "    step, modes, strats,\n",
    "    neighbors, categorical_transformer, random_state,\n",
    "    prelim_params, iteration, scoring_metrics, inner_cv,\n",
    "    X_train_outer, y_train_outer, groups_train_outer,\n",
    "    current_model, current_candidate_info, tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de19ec",
   "metadata": {},
   "source": [
    "#### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = results_history[-1]['Search Mode']\n",
    "strat = results_history[-1]['Imputasi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = \"Refine\"\n",
    "\n",
    "refine_param_dist = {\n",
    "    'model__C': loguniform(1e-1, 1e0),\n",
    "    'model__gamma': loguniform(5e-3, 5e-2),\n",
    "    'model__epsilon': loguniform(1e-1, 1e0)\n",
    "}\n",
    "\n",
    "refine_model, refine_results = full_implementation(\n",
    "    X_clean,\n",
    "    step, mode, strat,\n",
    "    neighbors, categorical_transformer, random_state,\n",
    "    refine_param_dist, iteration, scoring_metrics, inner_cv,\n",
    "    X_train_outer, y_train_outer, groups_train_outer,\n",
    "    prelim_best_model, prelim_best_results, tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86eae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "step2 = \"Refine 2nd\"\n",
    "\n",
    "refine_2nd_param_dist = {\n",
    "    'model__C': loguniform(1e-1, 5e-1),\n",
    "    'model__gamma': loguniform(1e-3, 1e-2),\n",
    "    'model__epsilon': loguniform(1e-1, 3e-1)\n",
    "}\n",
    "\n",
    "refine_2nd_model, refine_2nd_results = full_implementation(\n",
    "    X_clean,\n",
    "    step2, mode, strat,\n",
    "    neighbors, categorical_transformer, random_state,\n",
    "    refine_2nd_param_dist, iteration, scoring_metrics, inner_cv,\n",
    "    X_train_outer, y_train_outer, groups_train_outer,\n",
    "    refine_model, refine_results, tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step3 = \"Refine 3rd\"\n",
    "\n",
    "refine_3rd_param_dist = {\n",
    "    'model__C': loguniform(3e-1, 5e-1),\n",
    "    'model__gamma': loguniform(8e-4, 2e-3),\n",
    "    'model__epsilon': loguniform(6e-2, 2e-1)\n",
    "}\n",
    "\n",
    "refine_3rd_model, refine_3rd_results = full_implementation(\n",
    "    X_clean,\n",
    "    step3, mode, strat,\n",
    "    neighbors, categorical_transformer, random_state,\n",
    "    refine_3rd_param_dist, iteration, scoring_metrics, inner_cv,\n",
    "    X_train_outer, y_train_outer, groups_train_outer,\n",
    "    refine_2nd_model, refine_2nd_results, tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "step4 = \"Refine 4th\"\n",
    "\n",
    "refine_4th_param_dist = {\n",
    "    'model__C': loguniform(49e-2, 53e-2),\n",
    "    'model__gamma': loguniform(1e-3, 16e-4),\n",
    "    'model__epsilon': loguniform(5e-2, 9e-2)\n",
    "}\n",
    "\n",
    "refine_4th_model, refine_4th_results = full_implementation(\n",
    "    X_clean,\n",
    "    step4, mode, strat,\n",
    "    neighbors, categorical_transformer, random_state,\n",
    "    refine_4th_param_dist, iteration, scoring_metrics, inner_cv,\n",
    "    X_train_outer, y_train_outer, groups_train_outer,\n",
    "    refine_3rd_model, refine_3rd_results, tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ceffe8",
   "metadata": {},
   "source": [
    "#### Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d73782",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = refine_4th_model\n",
    "\n",
    "prediction, test_results = model_eval(best_model, X_test_outer, y_test_outer)\n",
    "\n",
    "print(\"Model performance on test set:\")\n",
    "for key, value in test_results.items():\n",
    "    if key.startswith('Test '):\n",
    "        label = key.replace('Test ', '').ljust(8)\n",
    "        print(f\" > {label} = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style agar plot terlihat rapi untuk publikasi\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 1. Siapkan Data dan Metrik\n",
    "y_actual = y_test_outer\n",
    "y_predicted = prediction\n",
    "r2_score = test_results['Test R²']\n",
    "rmse_score = test_results['Test RMSE']\n",
    "mae_score = test_results['Test MAE']\n",
    "\n",
    "# 2. Buat Canvas\n",
    "plt.figure(figsize=(9, 8)) # Ukuran agak persegi agar proporsional\n",
    "\n",
    "# 3. Plot Titik Scatter\n",
    "# alpha=0.6 membuat titik agak transparan, membantu melihat area yang padat data\n",
    "plt.scatter(y_actual, y_predicted,\n",
    "    color='royalblue', alpha=0.6, edgecolors='w', s=60,\n",
    "    label='Test Data Points'\n",
    ")\n",
    "\n",
    "# 4. Plot Garis Referensi Ideal (y=x)\n",
    "# Tentukan batas min dan max dari seluruh data agar garisnya pas\n",
    "data_min = min(y_actual.min(), y_predicted.min())\n",
    "data_max = max(y_actual.max(), y_predicted.max())\n",
    "# Tambah sedikit padding biar tidak mepet frame\n",
    "padding = (data_max - data_min) * 0.05\n",
    "limits = [data_min - padding, data_max + padding]\n",
    "\n",
    "plt.plot(limits, limits,\n",
    "    color='crimson', linestyle='--', linewidth=2.5,\n",
    "    label='Perfect Prediction ($y=x$)'\n",
    ")\n",
    "\n",
    "# 5. Labeling dan Judul\n",
    "plt.xlabel('Experimental Work Function (eV)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Predicted Work Function (eV)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Judul Informatif dengan Metrik\n",
    "title_text = f\"Final SVR Model Performance on Unseen Test Set\\n\"\n",
    "subtitle_text = f\"$R^2$ = {r2_score:.3f} | RMSE = {rmse_score:.3f} eV | MAE = {mae_score:.3f} eV\"\n",
    "plt.title(title_text + subtitle_text, fontsize=16, pad=20)\n",
    "\n",
    "# 6. Estetika Tambahan\n",
    "plt.legend(fontsize=12, loc='upper left')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlim(limits)\n",
    "plt.ylim(limits)\n",
    "plt.gca().set_aspect('equal', adjustable='box') # Memastikan skala sumbu X dan Y sama\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Simpan plot sebagai gambar resolusi tinggi (opsional, uncomment jika butuh)\n",
    "# plt.savefig('final_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc371c0",
   "metadata": {},
   "source": [
    "### Model's Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c760f44",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4028f",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2414660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi JS untuk plot SHAP di notebook\n",
    "shap.initjs()\n",
    "\n",
    "# --- PENTING! ---\n",
    "# Ambil model terbaik dari 3rd_fine_tune (PEMENANG KITA)\n",
    "best_shap_model = refine_4th_model.best_estimator_\n",
    "\n",
    "# Pisahkan preprocessor dan model SVR-nya\n",
    "preprocessor = best_shap_model.named_steps['preprocessor']\n",
    "svr_model = best_shap_model.named_steps['model']\n",
    "\n",
    "print(\"SHAP, model pemenang, dan preprocessor siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a827b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Memproses data train dan test...\")\n",
    "# Proses data mentah pakai preprocessor\n",
    "X_train_processed = preprocessor.transform(X_train_outer)\n",
    "X_test_processed = preprocessor.transform(X_test_outer)\n",
    "\n",
    "# Ambil nama fitur SETELAH di-OHE (ini krusial untuk plot)\n",
    "# Nama fiturnya akan jadi seperti: 'num__atomic_radius', 'cat__miller_index_(0, 0, 1)', dll.\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "clean_feature_names = [\n",
    "    f.replace('num__', '').replace('cat__structure_type_', '')\n",
    "    for f in feature_names\n",
    "]\n",
    "\n",
    "print(f\"Data diproses. Jumlah total fitur: {len(feature_names)}\")\n",
    "\n",
    "# --- PENTING: Buat DataFrame untuk plot ---\n",
    "# Ubah data test yang sudah diproses jadi DataFrame\n",
    "# Ini agar plot SHAP punya nama kolom yang benar\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=clean_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat 2 jenis ringkasan background data (K-Means)...\")\n",
    "\n",
    "background_data1 = shap.kmeans(X_train_processed, 50)\n",
    "background_data2 = shap.kmeans(X_train_processed, 100)\n",
    "\n",
    "print(\"2 jenis ringkasan background data siap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556cd73",
   "metadata": {},
   "source": [
    "##### SHAP values dan 3 jenis plot dari explainer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff887daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat KernelExplainer bernama explainer1...\")\n",
    "explainer1 = shap.KernelExplainer(svr_model.predict, background_data1)\n",
    "\n",
    "print(\"Mulai menghitung SHAP values menggunakan explainer1 untuk data test...\")\n",
    "shap_values1 = explainer1.shap_values(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 1: Global Feature Importance (Bar Plot) ---\n",
    "# Menunjukkan rata-rata dampak absolut. Fitur apa yang PALING PENTING?\n",
    "print(\"--- Global Feature Importance dari explainer1 (Bar) ---\")\n",
    "shap.summary_plot(shap_values1, X_test_processed_df, plot_type=\"bar\", show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# 3. Loop untuk setiap batang (bar) di grafik\n",
    "for p in ax.patches:\n",
    "    # Ambil lebar batang (ini adalah nilai rata-rata SHAP-nya)\n",
    "    width = p.get_width()\n",
    "    \n",
    "    # Tentukan posisi X dan Y untuk teks\n",
    "    # X sedikit digeser ke kanan dari ujung batang (width + offset kecil)\n",
    "    # Y tepat di tengah tinggi batang\n",
    "    x_pos = width + (width * 0.01) # Geser 1% ke kanan biar gak nempel\n",
    "    y_pos = p.get_y() + p.get_height() / 2\n",
    "    \n",
    "    # Tambahkan teks angka\n",
    "    # {:.4f} artinya ambil 4 angka di belakang koma\n",
    "    ax.text(x_pos, y_pos, f'{width:.3f}', \n",
    "            va='center', ha='left', fontsize=10, color='black')\n",
    "\n",
    "# 4. (Opsional) Perlebar batas kanan agar angka tidak terpotong\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax * 1.1) # Tambah 10% ruang di kanan\n",
    "\n",
    "# 5. Tampilkan hasil akhirnya\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 2: Beeswarm Summary Plot ---\n",
    "# Menunjukkan SETIAP data poin.\n",
    "# - Sumbu X = Nilai SHAP (dampak ke prediksi)\n",
    "# - Warna = Nilai fitur (Merah=Tinggi, Biru=Rendah)\n",
    "print(\"\\n--- SHAP Summary Plot dari explainer1 (Beeswarm) ---\")\n",
    "shap.summary_plot(shap_values1, X_test_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 3: Waterfall Plot (VERSI BARU YANG SUDAH DIPERBAIKI) ---\n",
    "\n",
    "# Kamu bisa ganti `idx_to_explain` ke angka lain (misal: 5, 10, 20)\n",
    "# untuk melihat data poin lain di test set.\n",
    "idx_to_explain = 0\n",
    "\n",
    "print(f\"--- Menampilkan Waterfall Plot untuk data poin ke-{idx_to_explain} dari explainer1 ---\")\n",
    "\n",
    "# --- PERBAIKANNYA DI SINI ---\n",
    "# 1. Buat 'Explanation' object secara manual untuk SATU data poin\n",
    "exp_one_sample = shap.Explanation(\n",
    "    values=shap_values1[idx_to_explain],\n",
    "    base_values=explainer1.expected_value,\n",
    "    data=X_test_processed_df.iloc[idx_to_explain].values, # Ambil nilainya\n",
    "    feature_names=X_test_processed_df.columns.tolist() # Ambil nama fiturnya\n",
    ")\n",
    "\n",
    "# 2. Sekarang, panggil waterfall_plot HANYA dengan SATU object itu\n",
    "shap.waterfall_plot(exp_one_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45d1ab",
   "metadata": {},
   "source": [
    "##### SHAP values dan 4 jenis plot dari explainer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat KernelExplainer bernama explainer2...\")\n",
    "explainer2 = shap.KernelExplainer(svr_model.predict, background_data2)\n",
    "\n",
    "print(\"Mulai menghitung SHAP values menggunakan explainer2 untuk data test...\")\n",
    "shap_values2 = explainer2.shap_values(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 1: Global Feature Importance (Bar Plot) ---\n",
    "# Menunjukkan rata-rata dampak absolut. Fitur apa yang PALING PENTING?\n",
    "print(\"--- Global Feature Importance dari explainer2 (Bar) ---\")\n",
    "shap.summary_plot(shap_values2, X_test_processed_df, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 2: Beeswarm Summary Plot ---\n",
    "# Menunjukkan SETIAP data poin.\n",
    "# - Sumbu X = Nilai SHAP (dampak ke prediksi)\n",
    "# - Warna = Nilai fitur (Merah=Tinggi, Biru=Rendah)\n",
    "print(\"\\n--- SHAP Summary Plot dari explainer2 (Beeswarm) ---\")\n",
    "shap.summary_plot(shap_values2, X_test_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 3: Waterfall Plot (VERSI BARU YANG SUDAH DIPERBAIKI) ---\n",
    "\n",
    "# Kamu bisa ganti `idx_to_explain` ke angka lain (misal: 5, 10, 20)\n",
    "# untuk melihat data poin lain di test set.\n",
    "idx_to_explain = 0\n",
    "\n",
    "print(f\"--- Menampilkan Waterfall Plot untuk data poin ke-{idx_to_explain} dari explainer2 ---\")\n",
    "\n",
    "# --- PERBAIKANNYA DI SINI ---\n",
    "# 1. Buat 'Explanation' object secara manual untuk SATU data poin\n",
    "exp_one_sample = shap.Explanation(\n",
    "    values=shap_values2[idx_to_explain],\n",
    "    base_values=explainer2.expected_value,\n",
    "    data=X_test_processed_df.iloc[idx_to_explain].values, # Ambil nilainya\n",
    "    feature_names=X_test_processed_df.columns.tolist() # Ambil nama fiturnya\n",
    ")\n",
    "\n",
    "# 2. Sekarang, panggil waterfall_plot HANYA dengan SATU object itu\n",
    "shap.waterfall_plot(exp_one_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e49469",
   "metadata": {},
   "source": [
    "##### SHAP values dan 4 jenis plot dari explainer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6934a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat KernelExplainer bernama explainer3...\")\n",
    "explainer3 = shap.KernelExplainer(svr_model.predict, X_train_processed)\n",
    "\n",
    "print(\"Mulai menghitung SHAP values menggunakan explainer3 untuk data test...\")\n",
    "shap_values3 = explainer3.shap_values(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 1: Global Feature Importance (Bar Plot) ---\n",
    "# Menunjukkan rata-rata dampak absolut. Fitur apa yang PALING PENTING?\n",
    "print(\"--- Global Feature Importance dari explainer3 (Bar) ---\")\n",
    "shap.summary_plot(shap_values3, X_test_processed_df, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42763c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 2: Beeswarm Summary Plot ---\n",
    "# Menunjukkan SETIAP data poin.\n",
    "# - Sumbu X = Nilai SHAP (dampak ke prediksi)\n",
    "# - Warna = Nilai fitur (Merah=Tinggi, Biru=Rendah)\n",
    "print(\"\\n--- SHAP Summary Plot dari explainer3 (Beeswarm) ---\")\n",
    "shap.summary_plot(shap_values3, X_test_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcfec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOT 3: Waterfall Plot (VERSI BARU YANG SUDAH DIPERBAIKI) ---\n",
    "\n",
    "# Kamu bisa ganti `idx_to_explain` ke angka lain (misal: 5, 10, 20)\n",
    "# untuk melihat data poin lain di test set.\n",
    "idx_to_explain = 0\n",
    "\n",
    "print(f\"--- Menampilkan Waterfall Plot untuk data poin ke-{idx_to_explain} dari explainer3 ---\")\n",
    "\n",
    "# --- PERBAIKANNYA DI SINI ---\n",
    "# 1. Buat 'Explanation' object secara manual untuk SATU data poin\n",
    "exp_one_sample = shap.Explanation(\n",
    "    values=shap_values3[idx_to_explain],\n",
    "    base_values=explainer3.expected_value,\n",
    "    data=X_test_processed_df.iloc[idx_to_explain].values, # Ambil nilainya\n",
    "    feature_names=X_test_processed_df.columns.tolist() # Ambil nama fiturnya\n",
    ")\n",
    "\n",
    "# 2. Sekarang, panggil waterfall_plot HANYA dengan SATU object itu\n",
    "shap.waterfall_plot(exp_one_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6861a",
   "metadata": {},
   "source": [
    "#### ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f587c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = refine_4th_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a030d3a",
   "metadata": {},
   "source": [
    "##### ALE plot from explainer1 SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Generating ALE Plots (Emergency Low-Res Mode)...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 1. Pastikan Ranking Dataframe siap\n",
    "mean_shap_values = np.abs(shap_values1).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': clean_feature_names,\n",
    "    'importance': mean_shap_values\n",
    "})\n",
    "top_11_df = importance_df.sort_values(by='importance', ascending=False).head(11)\n",
    "top_11_features = top_11_df['feature'].tolist()\n",
    "\n",
    "# 2. Loop Semua Fitur\n",
    "for i, feature_name in enumerate(top_11_features, 1):\n",
    "    \n",
    "    if feature_name not in X_train_outer.columns:\n",
    "        continue # Skip\n",
    "\n",
    "    print(f\"[{i}/11] Processing: {feature_name}...\", end=\" \")\n",
    "    \n",
    "    imp_score = top_11_df.iloc[i-1]['importance']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    success = False\n",
    "    status_msg = \"\"\n",
    "    \n",
    "    # --- LEVEL 1: STANDARD ---\n",
    "    try:\n",
    "        ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                      grid_size=50, include_CI=True)\n",
    "        success = True\n",
    "        status_msg = \"✅ Standard\"\n",
    "\n",
    "    except Exception:\n",
    "        # --- LEVEL 2: LOW RES (Grid=10, No CI) ---\n",
    "        # Biasanya Modulus butuh ini. Grid diturunkan drastis biar bins gak tabrakan.\n",
    "        try:\n",
    "            ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                          grid_size=10, include_CI=False) # Matikan CI\n",
    "            success = True\n",
    "            status_msg = \"⚠️ Low-Res (Grid=10)\"\n",
    "            \n",
    "        except Exception:\n",
    "            # --- LEVEL 3: ULTRA LOW RES + JITTER (Grid=5) ---\n",
    "            # Opsi Nuklir: Cuma minta 5 titik, plus data digoyang noise.\n",
    "            try:\n",
    "                X_temp = X_train_outer.copy()\n",
    "                std_val = X_temp[feature_name].std()\n",
    "                if std_val == 0: std_val = 1\n",
    "                \n",
    "                # Noise agak kasar (5%)\n",
    "                rng = np.random.RandomState(42)\n",
    "                X_temp[feature_name] += rng.normal(0, std_val * 0.05, size=len(X_temp))\n",
    "                \n",
    "                ale_eff = ale(X=X_temp, model=best_pipeline, feature=[feature_name], \n",
    "                              grid_size=5, include_CI=False)\n",
    "                success = True\n",
    "                status_msg = \"🚨 Ultra-Low (Grid=5)\"\n",
    "            except Exception as e_final:\n",
    "                print(f\"❌ GAGAL. Error: {e_final}\")\n",
    "                plt.close()\n",
    "                continue\n",
    "\n",
    "    if success:\n",
    "        plt.title(f\"#{i} ALE: {feature_name}\\n(SHAP: {imp_score:.4f})\", fontsize=12)\n",
    "        plt.xlabel(f\"{feature_name}\", fontsize=10)\n",
    "        plt.ylabel(\"Effect (eV)\", fontsize=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        print(status_msg)\n",
    "        plt.show()\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1313ae1",
   "metadata": {},
   "source": [
    "##### ALE plot from explainer2 SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Generating ALE Plots (Emergency Low-Res Mode)...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 1. Pastikan Ranking Dataframe siap\n",
    "mean_shap_values = np.abs(shap_values2).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': clean_feature_names,\n",
    "    'importance': mean_shap_values\n",
    "})\n",
    "top_11_df = importance_df.sort_values(by='importance', ascending=False).head(11)\n",
    "top_11_features = top_11_df['feature'].tolist()\n",
    "\n",
    "# 2. Loop Semua Fitur\n",
    "for i, feature_name in enumerate(top_11_features, 1):\n",
    "    \n",
    "    if feature_name not in X_train_outer.columns:\n",
    "        continue # Skip\n",
    "\n",
    "    print(f\"[{i}/11] Processing: {feature_name}...\", end=\" \")\n",
    "    \n",
    "    imp_score = top_11_df.iloc[i-1]['importance']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    success = False\n",
    "    status_msg = \"\"\n",
    "    \n",
    "    # --- LEVEL 1: STANDARD ---\n",
    "    try:\n",
    "        ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                      grid_size=50, include_CI=True)\n",
    "        success = True\n",
    "        status_msg = \"✅ Standard\"\n",
    "\n",
    "    except Exception:\n",
    "        # --- LEVEL 2: LOW RES (Grid=10, No CI) ---\n",
    "        # Biasanya Modulus butuh ini. Grid diturunkan drastis biar bins gak tabrakan.\n",
    "        try:\n",
    "            ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                          grid_size=10, include_CI=False) # Matikan CI\n",
    "            success = True\n",
    "            status_msg = \"⚠️ Low-Res (Grid=10)\"\n",
    "            \n",
    "        except Exception:\n",
    "            # --- LEVEL 3: ULTRA LOW RES + JITTER (Grid=5) ---\n",
    "            # Opsi Nuklir: Cuma minta 5 titik, plus data digoyang noise.\n",
    "            try:\n",
    "                X_temp = X_train_outer.copy()\n",
    "                std_val = X_temp[feature_name].std()\n",
    "                if std_val == 0: std_val = 1\n",
    "                \n",
    "                # Noise agak kasar (5%)\n",
    "                rng = np.random.RandomState(42)\n",
    "                X_temp[feature_name] += rng.normal(0, std_val * 0.05, size=len(X_temp))\n",
    "                \n",
    "                ale_eff = ale(X=X_temp, model=best_pipeline, feature=[feature_name], \n",
    "                              grid_size=5, include_CI=False)\n",
    "                success = True\n",
    "                status_msg = \"🚨 Ultra-Low (Grid=5)\"\n",
    "            except Exception as e_final:\n",
    "                print(f\"❌ GAGAL. Error: {e_final}\")\n",
    "                plt.close()\n",
    "                continue\n",
    "\n",
    "    if success:\n",
    "        plt.title(f\"#{i} ALE: {feature_name}\\n(SHAP: {imp_score:.4f})\", fontsize=12)\n",
    "        plt.xlabel(f\"{feature_name}\", fontsize=10)\n",
    "        plt.ylabel(\"Effect (eV)\", fontsize=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        print(status_msg)\n",
    "        plt.show()\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4ab72",
   "metadata": {},
   "source": [
    "##### ALE plot from explainer3 SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b146bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Generating ALE Plots (Emergency Low-Res Mode)...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 1. Pastikan Ranking Dataframe siap\n",
    "mean_shap_values = np.abs(shap_values3).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': clean_feature_names,\n",
    "    'importance': mean_shap_values\n",
    "})\n",
    "top_11_df = importance_df.sort_values(by='importance', ascending=False).head(11)\n",
    "top_11_features = top_11_df['feature'].tolist()\n",
    "\n",
    "# 2. Loop Semua Fitur\n",
    "for i, feature_name in enumerate(top_11_features, 1):\n",
    "    \n",
    "    if feature_name not in X_train_outer.columns:\n",
    "        continue # Skip\n",
    "\n",
    "    print(f\"[{i}/11] Processing: {feature_name}...\", end=\" \")\n",
    "    \n",
    "    imp_score = top_11_df.iloc[i-1]['importance']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    success = False\n",
    "    status_msg = \"\"\n",
    "    \n",
    "    # --- LEVEL 1: STANDARD ---\n",
    "    try:\n",
    "        ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                      grid_size=50, include_CI=True)\n",
    "        success = True\n",
    "        status_msg = \"✅ Standard\"\n",
    "\n",
    "    except Exception:\n",
    "        # --- LEVEL 2: LOW RES (Grid=10, No CI) ---\n",
    "        # Biasanya Modulus butuh ini. Grid diturunkan drastis biar bins gak tabrakan.\n",
    "        try:\n",
    "            ale_eff = ale(X=X_train_outer, model=best_pipeline, feature=[feature_name], \n",
    "                          grid_size=10, include_CI=False) # Matikan CI\n",
    "            success = True\n",
    "            status_msg = \"⚠️ Low-Res (Grid=10)\"\n",
    "            \n",
    "        except Exception:\n",
    "            # --- LEVEL 3: ULTRA LOW RES + JITTER (Grid=5) ---\n",
    "            # Opsi Nuklir: Cuma minta 5 titik, plus data digoyang noise.\n",
    "            try:\n",
    "                X_temp = X_train_outer.copy()\n",
    "                std_val = X_temp[feature_name].std()\n",
    "                if std_val == 0: std_val = 1\n",
    "                \n",
    "                # Noise agak kasar (5%)\n",
    "                rng = np.random.RandomState(42)\n",
    "                X_temp[feature_name] += rng.normal(0, std_val * 0.05, size=len(X_temp))\n",
    "                \n",
    "                ale_eff = ale(X=X_temp, model=best_pipeline, feature=[feature_name], \n",
    "                              grid_size=5, include_CI=False)\n",
    "                success = True\n",
    "                status_msg = \"🚨 Ultra-Low (Grid=5)\"\n",
    "            except Exception as e_final:\n",
    "                print(f\"❌ GAGAL. Error: {e_final}\")\n",
    "                plt.close()\n",
    "                continue\n",
    "\n",
    "    if success:\n",
    "        plt.title(f\"#{i} ALE: {feature_name}\\n(SHAP: {imp_score:.4f})\", fontsize=12)\n",
    "        plt.xlabel(f\"{feature_name}\", fontsize=10)\n",
    "        plt.ylabel(\"Effect (eV)\", fontsize=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        print(status_msg)\n",
    "        plt.show()\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
